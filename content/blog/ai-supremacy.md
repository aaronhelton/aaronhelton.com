---
title: "AI Supremacy: Why Principled Technocrats and Technologists Are Losing"
date: 2024-11-23
author: "S. Nightingale"
tags: ['ai','technology','politics']
---

It is important, even vital, for the principled technocrats and technologists to maintain their skepticism in the face of the growing "AI" threat, even to the point being and acting as the opposition. And yet we are losing. We probably will lose. "AI" is the populist demagogue of technology, singing a siren song of promises to fix what's broken. And people are listening.

We imagine ourselves, perhaps, as treading in the bloody footprints of Ned Ludd, ready at a moment's notice to smash these new looms that weave "information" from the pilfered fibers of the Internet. We smugly point out that the Luddites were right to fear the fruits of automation, and right to stand against them. But we can be right and still find ourselves in a rearguard battle as a hydra of misinformation closes off any hope of escape.

Unlike the Luddites, however, we have put ourselves here, because as technocrats and technologists, we have failed our users. What they want are tools to make their lives easier, to help them process increasing workloads efficiently, ultimately to better serve *their* users, as they imagine it. We have, of course, endeavored to deliver these tools, and we've developed ever more baroque and at times ideological rituals in our quest to deliver them. Through our mantras of user stories and agile development (that usually isn't agile at all), and our adherence to the the false religions of project management and performance management, we've anesthetized ourselves into gating off useful technologies.

And our users? They are discovering that ready access to "AI", at least in its current LLM incarnation, a planet-devouring Ouroboros with a silver tongue and a penchant for just making shit up, offers a way past the wizened gates of the tehcnologists and technocrats, who are busy salting runes on the floors of their offices in the hopes of staving off project failure.

Users are voting. They will seek out and use these tools, which they know to be deeply flawed and probably dangerous, because these flawed and dangerous tools possess a different set of flaws and dangers from those of the technology gatekeepers. We've told them in the past that change is good, that change is inevitable, and that change means progress. Or some of us have, anyway, and our users have internalized this message. They will seize these tools and attempt to beat us at our own game. Since there are more of them than there are of us, they will likely succeed, if not on quality, then on strength of numbers alone.